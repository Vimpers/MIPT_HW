{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 106ms/step - accuracy: 0.6282 - loss: 1.0662 - val_accuracy: 0.8297 - val_loss: 0.4758\n",
      "Epoch 2/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.8208 - loss: 0.4937 - val_accuracy: 0.8574 - val_loss: 0.4005\n",
      "Epoch 3/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 116ms/step - accuracy: 0.8497 - loss: 0.4182 - val_accuracy: 0.8719 - val_loss: 0.3610\n",
      "Epoch 4/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - accuracy: 0.8635 - loss: 0.3809 - val_accuracy: 0.8800 - val_loss: 0.3372\n",
      "Epoch 5/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.8702 - loss: 0.3612 - val_accuracy: 0.8870 - val_loss: 0.3155\n",
      "Epoch 6/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - accuracy: 0.8801 - loss: 0.3358 - val_accuracy: 0.8938 - val_loss: 0.3007\n",
      "Epoch 7/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.8852 - loss: 0.3163 - val_accuracy: 0.8976 - val_loss: 0.2925\n",
      "Epoch 8/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - accuracy: 0.8922 - loss: 0.2964 - val_accuracy: 0.8946 - val_loss: 0.2915\n",
      "Epoch 9/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.8928 - loss: 0.2940 - val_accuracy: 0.9015 - val_loss: 0.2759\n",
      "Epoch 10/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.8975 - loss: 0.2838 - val_accuracy: 0.9031 - val_loss: 0.2719\n",
      "Epoch 11/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 145ms/step - accuracy: 0.9000 - loss: 0.2714 - val_accuracy: 0.9055 - val_loss: 0.2670\n",
      "Epoch 12/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - accuracy: 0.9015 - loss: 0.2680 - val_accuracy: 0.9062 - val_loss: 0.2653\n",
      "Epoch 13/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.9035 - loss: 0.2585 - val_accuracy: 0.9112 - val_loss: 0.2519\n",
      "Epoch 14/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - accuracy: 0.9095 - loss: 0.2474 - val_accuracy: 0.9119 - val_loss: 0.2506\n",
      "Epoch 15/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9119 - loss: 0.2409 - val_accuracy: 0.9058 - val_loss: 0.2602\n",
      "Epoch 16/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - accuracy: 0.9096 - loss: 0.2429 - val_accuracy: 0.9097 - val_loss: 0.2565\n",
      "Epoch 17/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - accuracy: 0.9169 - loss: 0.2287 - val_accuracy: 0.9153 - val_loss: 0.2423\n",
      "Epoch 18/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9154 - loss: 0.2250 - val_accuracy: 0.9153 - val_loss: 0.2357\n",
      "Epoch 19/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.9213 - loss: 0.2159 - val_accuracy: 0.9143 - val_loss: 0.2380\n",
      "Epoch 20/20\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9167 - loss: 0.2177 - val_accuracy: 0.9139 - val_loss: 0.2398\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "train_file_path = \"C:/Users/Petroo/Desktop/fashion-mnist_train.csv\"\n",
    "test_file_path = \"C:/Users/Petroo/Desktop/fashion-mnist_test.csv\"\n",
    "\n",
    "    # Проверямем верно ли указано расположение файлов\n",
    "if os.path.exists(train_file_path) and os.path.exists(test_file_path):\n",
    "    # Загружаем данные\n",
    "    train_data_df = pd.read_csv (train_file_path)\n",
    "    test_data_df = pd.read_csv (test_file_path)\n",
    "\n",
    "    # Преобразовываем данные из pandas DataFrame в numpy массивы\n",
    "    train_data = np.array (train_data_df, dtype='float32')\n",
    "    test_data = np.array (test_data_df, dtype='float32')\n",
    "\n",
    "    # Разделяем данные на признаки и метки\n",
    "    x_train = train_data [:, 1:] / 255\n",
    "    y_train = train_data [:, 0]\n",
    "\n",
    "\n",
    "    x_test = test_data [:, 1:] / 255\n",
    "    y_test = test_data [:, 0]\n",
    "\n",
    "    # Разделяем данные на обучающую и тестовые выборки\n",
    "    x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=228)\n",
    "\n",
    "    # Добавляем параметры размера изображений и для настройки слоев нейронной сети и модели обучения, \n",
    "    # что позволит быстро вносить необходимые изменения \n",
    "\n",
    "    class ImgSettings:\n",
    "        img_rows = 28\n",
    "        img_cols = 28\n",
    "        \n",
    "        @classmethod\n",
    "        def get_img_shape(cls) -> tuple:\n",
    "            return cls.img_rows, cls.img_cols, 1\n",
    "        \n",
    "        @classmethod\n",
    "        def reshape(cls, x: np.ndarray) -> np.ndarray:\n",
    "            return x.reshape(x.shape[0], cls.img_rows, cls.img_cols, 1)\n",
    "        \n",
    "    class LayersSettings:\n",
    "        filters = 32\n",
    "        kernel_size = 3\n",
    "        activation = 'relu'\n",
    "        pool_size = 2\n",
    "        dropout = 0.3\n",
    "        dense = 128\n",
    "        dense_activation = 'relu'\n",
    "        output = 10\n",
    "        output_activation = 'softmax'\n",
    "\n",
    "    class ModelSettings:\n",
    "        number_epochs = 20\n",
    "        verbose = 1\n",
    "        batch_size = 256\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "\n",
    "    # совмещаем форму входных данных\n",
    "    x_train = ImgSettings.reshape(x_train)\n",
    "    x_test = ImgSettings.reshape(x_test)\n",
    "    x_validate = ImgSettings.reshape(x_validate)\n",
    "\n",
    "\n",
    "    # Создаём модель\n",
    "    model = models.Sequential()\n",
    "    # Входной слой\n",
    "    model.add(layers.Input(shape=ImgSettings.get_img_shape()))\n",
    "    # Первый сверточный слой\n",
    "    model.add(layers.Conv2D(filters=LayersSettings.filters, kernel_size=LayersSettings.kernel_size, activation=LayersSettings.activation))\n",
    "    # Слой подвыборки\n",
    "    model.add(layers.MaxPooling2D(pool_size=LayersSettings.pool_size))\n",
    "    # Слой дропаута для предотвращения переобучения\n",
    "    model.add(layers.Dropout(LayersSettings.dropout))\n",
    "    # Второй сверточный слой\n",
    "    model.add(layers.Conv2D(filters=LayersSettings.filters*2, kernel_size=LayersSettings.kernel_size, activation=LayersSettings.activation))\n",
    "    # Второй слой подвыборки\n",
    "    model.add(layers.MaxPooling2D(pool_size=LayersSettings.pool_size))\n",
    "    # Второй слой дропаута\n",
    "    model.add(layers.Dropout(LayersSettings.dropout))\n",
    "    # Преобразование 3D данных в 1D\n",
    "    model.add(layers.Flatten())\n",
    "    # Полносвязный слой\n",
    "    model.add(layers.Dense(LayersSettings.dense, activation=LayersSettings.dense_activation))\n",
    "    # Выходной слой\n",
    "    model.add(layers.Dense(LayersSettings.output, activation=LayersSettings.output_activation))\n",
    "\n",
    "    # Компиляция модели\n",
    "    model.compile(optimizer='adam', loss=ModelSettings.loss, metrics=ModelSettings.metrics)\n",
    "\n",
    "    # Обучение модели\n",
    "    model.fit(x_train, y_train, batch_size=ModelSettings.batch_size, epochs=ModelSettings.number_epochs, verbose=ModelSettings.verbose, validation_data=(x_validate, y_validate))\n",
    "\n",
    "    # Оценка модели на тестовом наборе данных\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "    # Сохранение предсказаний в файл\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': np.arange(len(y_test_pred_classes)),\n",
    "        'Category': y_test_pred_classes\n",
    "    })\n",
    "    submission.to_csv(\"C:/Users/Petroo/Desktop/data/sample_submission.csv\", index=False)\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
